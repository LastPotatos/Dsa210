{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83eddcbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: yfinance in c:\\users\\han aga\\desktop\\dsa 210 anime\\python.venv\\lib\\site-packages (0.2.66)\n",
      "Requirement already satisfied: pandas>=1.3.0 in c:\\users\\han aga\\desktop\\dsa 210 anime\\python.venv\\lib\\site-packages (from yfinance) (2.3.3)\n",
      "Requirement already satisfied: numpy>=1.16.5 in c:\\users\\han aga\\desktop\\dsa 210 anime\\python.venv\\lib\\site-packages (from yfinance) (2.3.5)\n",
      "Requirement already satisfied: requests>=2.31 in c:\\users\\han aga\\desktop\\dsa 210 anime\\python.venv\\lib\\site-packages (from yfinance) (2.32.5)\n",
      "Requirement already satisfied: multitasking>=0.0.7 in c:\\users\\han aga\\desktop\\dsa 210 anime\\python.venv\\lib\\site-packages (from yfinance) (0.0.12)\n",
      "Requirement already satisfied: platformdirs>=2.0.0 in c:\\users\\han aga\\desktop\\dsa 210 anime\\python.venv\\lib\\site-packages (from yfinance) (4.5.0)\n",
      "Requirement already satisfied: pytz>=2022.5 in c:\\users\\han aga\\desktop\\dsa 210 anime\\python.venv\\lib\\site-packages (from yfinance) (2025.2)\n",
      "Requirement already satisfied: frozendict>=2.3.4 in c:\\users\\han aga\\desktop\\dsa 210 anime\\python.venv\\lib\\site-packages (from yfinance) (2.4.7)\n",
      "Requirement already satisfied: peewee>=3.16.2 in c:\\users\\han aga\\desktop\\dsa 210 anime\\python.venv\\lib\\site-packages (from yfinance) (3.18.3)\n",
      "Requirement already satisfied: beautifulsoup4>=4.11.1 in c:\\users\\han aga\\desktop\\dsa 210 anime\\python.venv\\lib\\site-packages (from yfinance) (4.14.2)\n",
      "Requirement already satisfied: curl_cffi>=0.7 in c:\\users\\han aga\\desktop\\dsa 210 anime\\python.venv\\lib\\site-packages (from yfinance) (0.13.0)\n",
      "Requirement already satisfied: protobuf>=3.19.0 in c:\\users\\han aga\\desktop\\dsa 210 anime\\python.venv\\lib\\site-packages (from yfinance) (6.33.1)\n",
      "Requirement already satisfied: websockets>=13.0 in c:\\users\\han aga\\desktop\\dsa 210 anime\\python.venv\\lib\\site-packages (from yfinance) (15.0.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\han aga\\desktop\\dsa 210 anime\\python.venv\\lib\\site-packages (from beautifulsoup4>=4.11.1->yfinance) (2.8)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\han aga\\desktop\\dsa 210 anime\\python.venv\\lib\\site-packages (from beautifulsoup4>=4.11.1->yfinance) (4.15.0)\n",
      "Requirement already satisfied: cffi>=1.12.0 in c:\\users\\han aga\\desktop\\dsa 210 anime\\python.venv\\lib\\site-packages (from curl_cffi>=0.7->yfinance) (2.0.0)\n",
      "Requirement already satisfied: certifi>=2024.2.2 in c:\\users\\han aga\\desktop\\dsa 210 anime\\python.venv\\lib\\site-packages (from curl_cffi>=0.7->yfinance) (2025.11.12)\n",
      "Requirement already satisfied: pycparser in c:\\users\\han aga\\desktop\\dsa 210 anime\\python.venv\\lib\\site-packages (from cffi>=1.12.0->curl_cffi>=0.7->yfinance) (2.23)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\han aga\\desktop\\dsa 210 anime\\python.venv\\lib\\site-packages (from pandas>=1.3.0->yfinance) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\han aga\\desktop\\dsa 210 anime\\python.venv\\lib\\site-packages (from pandas>=1.3.0->yfinance) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\han aga\\desktop\\dsa 210 anime\\python.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.3.0->yfinance) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\han aga\\desktop\\dsa 210 anime\\python.venv\\lib\\site-packages (from requests>=2.31->yfinance) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\han aga\\desktop\\dsa 210 anime\\python.venv\\lib\\site-packages (from requests>=2.31->yfinance) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\han aga\\desktop\\dsa 210 anime\\python.venv\\lib\\site-packages (from requests>=2.31->yfinance) (2.5.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in c:\\users\\han aga\\desktop\\dsa 210 anime\\python.venv\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\han aga\\desktop\\dsa 210 anime\\python.venv\\lib\\site-packages (from tqdm) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install yfinance\n",
    "!pip install tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12a40284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 39 studios\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching data:   0%|          | 0/39 [00:00<?, ?it/s]C:\\Users\\Han Aga\\AppData\\Local\\Temp\\ipykernel_11100\\522293094.py:83: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
      "  hist[\"Quarter\"] = hist.index.to_period(\"Q\")\n",
      "Fetching data:   3%|▎         | 1/39 [00:02<01:20,  2.11s/it]HTTP Error 404: {\"quoteSummary\":{\"result\":null,\"error\":{\"code\":\"Not Found\",\"description\":\"Quote not found for symbol: WIT STUDIO, SIGNAL.MD), TYO:3791\"}}}\n",
      "$WIT STUDIO, SIGNAL.MD), TYO:3791: possibly delisted; no timezone found\n",
      "Fetching data:   5%|▌         | 2/39 [00:03<01:07,  1.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO DATA: IG Port (Production I.G (Wit Studio, Signal.MD), TYO:3791)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Han Aga\\AppData\\Local\\Temp\\ipykernel_11100\\522293094.py:83: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
      "  hist[\"Quarter\"] = hist.index.to_period(\"Q\")\n",
      "Fetching data:   8%|▊         | 3/39 [00:04<00:51,  1.44s/it]HTTP Error 404: {\"quoteSummary\":{\"result\":null,\"error\":{\"code\":\"Not Found\",\"description\":\"Quote not found for symbol: CRUNCHYROLL), TYO:6758\"}}}\n",
      "$CRUNCHYROLL), TYO:6758: possibly delisted; no timezone found\n",
      "Fetching data:  10%|█         | 4/39 [00:06<00:49,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO DATA: Sony Group (Aniplex (Crunchyroll), TYO:6758)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Han Aga\\AppData\\Local\\Temp\\ipykernel_11100\\522293094.py:83: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
      "  hist[\"Quarter\"] = hist.index.to_period(\"Q\")\n",
      "Fetching data:  13%|█▎        | 5/39 [00:06<00:39,  1.17s/it]C:\\Users\\Han Aga\\AppData\\Local\\Temp\\ipykernel_11100\\522293094.py:83: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
      "  hist[\"Quarter\"] = hist.index.to_period(\"Q\")\n",
      "Fetching data:  15%|█▌        | 6/39 [00:07<00:35,  1.08s/it]C:\\Users\\Han Aga\\AppData\\Local\\Temp\\ipykernel_11100\\522293094.py:83: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
      "  hist[\"Quarter\"] = hist.index.to_period(\"Q\")\n",
      "Fetching data:  18%|█▊        | 7/39 [00:08<00:30,  1.04it/s]HTTP Error 404: {\"quoteSummary\":{\"result\":null,\"error\":{\"code\":\"Not Found\",\"description\":\"Quote not found for symbol: SUPPORTS ANIME), TYO:4751\"}}}\n",
      "$SUPPORTS ANIME), TYO:4751: possibly delisted; no timezone found\n",
      "Fetching data:  21%|██        | 8/39 [00:09<00:33,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO DATA: CyberAgent (Owner of Abema (supports anime), TYO:4751)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Han Aga\\AppData\\Local\\Temp\\ipykernel_11100\\522293094.py:83: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
      "  hist[\"Quarter\"] = hist.index.to_period(\"Q\")\n",
      "Fetching data:  23%|██▎       | 9/39 [00:10<00:31,  1.03s/it]C:\\Users\\Han Aga\\AppData\\Local\\Temp\\ipykernel_11100\\522293094.py:83: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
      "  hist[\"Quarter\"] = hist.index.to_period(\"Q\")\n",
      "Fetching data:  26%|██▌       | 10/39 [00:11<00:29,  1.01s/it]C:\\Users\\Han Aga\\AppData\\Local\\Temp\\ipykernel_11100\\522293094.py:83: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
      "  hist[\"Quarter\"] = hist.index.to_period(\"Q\")\n",
      "Fetching data:  28%|██▊       | 11/39 [00:12<00:27,  1.03it/s]C:\\Users\\Han Aga\\AppData\\Local\\Temp\\ipykernel_11100\\522293094.py:83: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
      "  hist[\"Quarter\"] = hist.index.to_period(\"Q\")\n",
      "Fetching data:  31%|███       | 12/39 [00:13<00:25,  1.06it/s]C:\\Users\\Han Aga\\AppData\\Local\\Temp\\ipykernel_11100\\522293094.py:83: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
      "  hist[\"Quarter\"] = hist.index.to_period(\"Q\")\n",
      "Fetching data:  33%|███▎      | 13/39 [00:14<00:23,  1.08it/s]C:\\Users\\Han Aga\\AppData\\Local\\Temp\\ipykernel_11100\\522293094.py:83: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
      "  hist[\"Quarter\"] = hist.index.to_period(\"Q\")\n",
      "Fetching data:  36%|███▌      | 14/39 [00:15<00:22,  1.10it/s]HTTP Error 404: {\"quoteSummary\":{\"result\":null,\"error\":{\"code\":\"Not Found\",\"description\":\"Quote not found for symbol: LTD., TYO:9602\"}}}\n",
      "$LTD., TYO:9602: possibly delisted; no timezone found\n",
      "Fetching data:  38%|███▊      | 15/39 [00:16<00:26,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO DATA: Toho Co. (Ltd., TYO:9602)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP Error 404: {\"quoteSummary\":{\"result\":null,\"error\":{\"code\":\"Not Found\",\"description\":\"Quote not found for symbol: LTD., TYO:9601\"}}}\n",
      "$LTD., TYO:9601: possibly delisted; no timezone found\n",
      "Fetching data:  41%|████      | 16/39 [00:18<00:27,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO DATA: Shochiku Co. (Ltd., TYO:9601)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Han Aga\\AppData\\Local\\Temp\\ipykernel_11100\\522293094.py:83: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
      "  hist[\"Quarter\"] = hist.index.to_period(\"Q\")\n",
      "Fetching data:  44%|████▎     | 17/39 [00:18<00:22,  1.02s/it]C:\\Users\\Han Aga\\AppData\\Local\\Temp\\ipykernel_11100\\522293094.py:83: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
      "  hist[\"Quarter\"] = hist.index.to_period(\"Q\")\n",
      "Fetching data:  46%|████▌     | 18/39 [00:19<00:21,  1.01s/it]HTTP Error 404: {\"quoteSummary\":{\"result\":null,\"error\":{\"code\":\"Not Found\",\"description\":\"Quote not found for symbol: NOT PUBLIC)\"}}}\n",
      "$NOT PUBLIC): possibly delisted; no timezone found\n",
      "Fetching data:  49%|████▊     | 19/39 [00:20<00:19,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO DATA: Shueisha (part of Hitotsubashi Group (not public))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Han Aga\\AppData\\Local\\Temp\\ipykernel_11100\\522293094.py:83: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
      "  hist[\"Quarter\"] = hist.index.to_period(\"Q\")\n",
      "Fetching data:  51%|█████▏    | 20/39 [00:21<00:18,  1.04it/s]C:\\Users\\Han Aga\\AppData\\Local\\Temp\\ipykernel_11100\\522293094.py:83: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
      "  hist[\"Quarter\"] = hist.index.to_period(\"Q\")\n",
      "Fetching data:  54%|█████▍    | 21/39 [00:22<00:16,  1.11it/s]C:\\Users\\Han Aga\\AppData\\Local\\Temp\\ipykernel_11100\\522293094.py:83: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
      "  hist[\"Quarter\"] = hist.index.to_period(\"Q\")\n",
      "Fetching data:  56%|█████▋    | 22/39 [00:23<00:15,  1.13it/s]HTTP Error 404: {\"quoteSummary\":{\"result\":null,\"error\":{\"code\":\"Not Found\",\"description\":\"Quote not found for symbol: ANIME COLLABS), TYO:8136\"}}}\n",
      "$ANIME COLLABS), TYO:8136: possibly delisted; no timezone found\n",
      "Fetching data:  59%|█████▉    | 23/39 [00:24<00:15,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO DATA: Sanrio (Hello Kitty (anime collabs), TYO:8136)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$2706.T: possibly delisted; no timezone found\n",
      "Fetching data:  62%|██████▏   | 24/39 [00:25<00:14,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO DATA: Broccoli Co. (Merch & anime goods) (2706.T)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP Error 404: {\"quoteSummary\":{\"result\":null,\"error\":{\"code\":\"Not Found\",\"description\":\"Quote not found for symbol: NOT PUBLIC)\"}}}\n",
      "$NOT PUBLIC): possibly delisted; no timezone found\n",
      "Fetching data:  64%|██████▍   | 25/39 [00:26<00:14,  1.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO DATA: King Records (Starchild) (Owned by Kodansha (not public))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Han Aga\\AppData\\Local\\Temp\\ipykernel_11100\\522293094.py:83: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
      "  hist[\"Quarter\"] = hist.index.to_period(\"Q\")\n",
      "Fetching data:  67%|██████▋   | 26/39 [00:27<00:14,  1.10s/it]C:\\Users\\Han Aga\\AppData\\Local\\Temp\\ipykernel_11100\\522293094.py:83: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
      "  hist[\"Quarter\"] = hist.index.to_period(\"Q\")\n",
      "Fetching data:  69%|██████▉   | 27/39 [00:28<00:12,  1.06s/it]C:\\Users\\Han Aga\\AppData\\Local\\Temp\\ipykernel_11100\\522293094.py:83: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
      "  hist[\"Quarter\"] = hist.index.to_period(\"Q\")\n",
      "Fetching data:  72%|███████▏  | 28/39 [00:29<00:10,  1.07it/s]C:\\Users\\Han Aga\\AppData\\Local\\Temp\\ipykernel_11100\\522293094.py:83: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
      "  hist[\"Quarter\"] = hist.index.to_period(\"Q\")\n",
      "Fetching data:  74%|███████▍  | 29/39 [00:30<00:09,  1.11it/s]C:\\Users\\Han Aga\\AppData\\Local\\Temp\\ipykernel_11100\\522293094.py:83: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
      "  hist[\"Quarter\"] = hist.index.to_period(\"Q\")\n",
      "Fetching data:  77%|███████▋  | 30/39 [00:31<00:07,  1.13it/s]C:\\Users\\Han Aga\\AppData\\Local\\Temp\\ipykernel_11100\\522293094.py:83: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
      "  hist[\"Quarter\"] = hist.index.to_period(\"Q\")\n",
      "Fetching data:  79%|███████▉  | 31/39 [00:32<00:07,  1.06it/s]C:\\Users\\Han Aga\\AppData\\Local\\Temp\\ipykernel_11100\\522293094.py:83: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
      "  hist[\"Quarter\"] = hist.index.to_period(\"Q\")\n",
      "Fetching data:  82%|████████▏ | 32/39 [00:32<00:06,  1.10it/s]C:\\Users\\Han Aga\\AppData\\Local\\Temp\\ipykernel_11100\\522293094.py:83: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
      "  hist[\"Quarter\"] = hist.index.to_period(\"Q\")\n",
      "Fetching data:  85%|████████▍ | 33/39 [00:33<00:05,  1.12it/s]C:\\Users\\Han Aga\\AppData\\Local\\Temp\\ipykernel_11100\\522293094.py:83: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
      "  hist[\"Quarter\"] = hist.index.to_period(\"Q\")\n",
      "Fetching data:  87%|████████▋ | 34/39 [00:34<00:04,  1.16it/s]$9437.T: possibly delisted; no timezone found\n",
      "Fetching data:  90%|████████▉ | 35/39 [00:35<00:03,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO DATA: NTT Docomo (Anime collaborations) (9437.T)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Han Aga\\AppData\\Local\\Temp\\ipykernel_11100\\522293094.py:83: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
      "  hist[\"Quarter\"] = hist.index.to_period(\"Q\")\n",
      "Fetching data:  92%|█████████▏| 36/39 [00:36<00:02,  1.05it/s]C:\\Users\\Han Aga\\AppData\\Local\\Temp\\ipykernel_11100\\522293094.py:83: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
      "  hist[\"Quarter\"] = hist.index.to_period(\"Q\")\n",
      "Fetching data:  95%|█████████▍| 37/39 [00:37<00:01,  1.10it/s]C:\\Users\\Han Aga\\AppData\\Local\\Temp\\ipykernel_11100\\522293094.py:83: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
      "  hist[\"Quarter\"] = hist.index.to_period(\"Q\")\n",
      "Fetching data:  97%|█████████▋| 38/39 [00:38<00:00,  1.09it/s]C:\\Users\\Han Aga\\AppData\\Local\\Temp\\ipykernel_11100\\522293094.py:83: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
      "  hist[\"Quarter\"] = hist.index.to_period(\"Q\")\n",
      "Fetching data: 100%|██████████| 39/39 [00:39<00:00,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DONE\n",
      "Files created:\n",
      "- quarterly_linear_interpolated.csv\n",
      "- quarterly_linear_interpolated.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# Helpers\n",
    "# -----------------------\n",
    "\n",
    "def normalize_ticker(raw):\n",
    "    raw = raw.strip()\n",
    "\n",
    "    if \":\" in raw:\n",
    "        exch, code = raw.split(\":\", 1)\n",
    "        exch = exch.upper()\n",
    "\n",
    "        if exch in (\"TYO\", \"TSE\", \"JPX\"):\n",
    "            return f\"{code}.T\"\n",
    "        if exch == \"NASDAQ\":\n",
    "            return code\n",
    "        if exch == \"NYSE\":\n",
    "            return code\n",
    "\n",
    "    return raw\n",
    "\n",
    "\n",
    "def read_studios(path=\"studios.txt\"):\n",
    "    studios = []\n",
    "\n",
    "    with open(path, \"r\", encoding=\"utf-8-sig\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "\n",
    "            if not line or line.startswith(\"#\"):\n",
    "                continue\n",
    "\n",
    "            if \",\" not in line:\n",
    "                continue\n",
    "\n",
    "            name, tick = line.split(\",\", 1)\n",
    "            studios.append((name.strip(), normalize_ticker(tick)))\n",
    "\n",
    "    print(f\"Loaded {len(studios)} studios\")\n",
    "    return studios\n",
    "\n",
    "\n",
    "def build_quarter_index(series):\n",
    "    start = series.index.min()\n",
    "    end = series.index.max()\n",
    "    return pd.period_range(start=start, end=end, freq=\"Q\")\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# Main\n",
    "# -----------------------\n",
    "\n",
    "def main():\n",
    "    studios = read_studios(\"studios.txt\")\n",
    "\n",
    "    company_data = {}\n",
    "    all_quarters = set()\n",
    "\n",
    "    for name, ticker in tqdm(studios, desc=\"Fetching data\"):\n",
    "        try:\n",
    "            tk = yf.Ticker(ticker)\n",
    "            info = tk.info or {}\n",
    "            shares = info.get(\"sharesOutstanding\")\n",
    "\n",
    "            hist = tk.history(period=\"max\", auto_adjust=False)\n",
    "\n",
    "            if hist.empty:\n",
    "                print(f\"NO DATA: {name} ({ticker})\")\n",
    "                continue\n",
    "\n",
    "            if shares and shares > 0:\n",
    "                hist[\"MC\"] = hist[\"Close\"] * shares\n",
    "            else:\n",
    "                hist[\"MC\"] = hist[\"Close\"]\n",
    "\n",
    "            hist[\"Quarter\"] = hist.index.to_period(\"Q\")\n",
    "            q = hist.groupby(\"Quarter\")[\"MC\"].last()\n",
    "\n",
    "            if q.notna().sum() < 2:\n",
    "                print(f\"INSUFFICIENT DATA: {name}\")\n",
    "                continue\n",
    "\n",
    "            company_data[name] = q\n",
    "            all_quarters.update(q.index)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"FAILED {name}: {e}\")\n",
    "\n",
    "    # -----------------------\n",
    "    # Build master table\n",
    "    # -----------------------\n",
    "\n",
    "    quarters = sorted(all_quarters)\n",
    "    master = pd.DataFrame(index=quarters)\n",
    "\n",
    "    for name, series in company_data.items():\n",
    "        full_q = build_quarter_index(series)\n",
    "        series = series.reindex(full_q)\n",
    "        series = series.interpolate(method=\"linear\")\n",
    "        master[name] = series.reindex(quarters)\n",
    "\n",
    "    master[\"TotalValue\"] = master.sum(axis=1)\n",
    "\n",
    "    # -----------------------\n",
    "    # CSV\n",
    "    # -----------------------\n",
    "\n",
    "    master.reset_index().to_csv(\n",
    "        \"quarterly_linear_interpolated.csv\",\n",
    "        index=False,\n",
    "        float_format=\"%.2f\"\n",
    "    )\n",
    "\n",
    "    # -----------------------\n",
    "    # XML\n",
    "    # -----------------------\n",
    "\n",
    "    root = ET.Element(\"QuarterlyValues\")\n",
    "\n",
    "    for q in master.index:\n",
    "        q_el = ET.SubElement(root, \"Quarter\", value=str(q))\n",
    "        total = ET.SubElement(q_el, \"TotalValue\")\n",
    "        total.text = f\"{master.at[q, 'TotalValue']:.2f}\"\n",
    "\n",
    "        for name in company_data:\n",
    "            val = master.at[q, name]\n",
    "            if pd.notna(val):\n",
    "                c = ET.SubElement(q_el, \"Company\", name=name)\n",
    "                c.text = f\"{val:.2f}\"\n",
    "\n",
    "    ET.ElementTree(root).write(\n",
    "        \"quarterly_linear_interpolated.xml\",\n",
    "        encoding=\"utf-8\",\n",
    "        xml_declaration=True\n",
    "    )\n",
    "\n",
    "    print(\"\\nDONE\")\n",
    "    print(\"Files created:\")\n",
    "    print(\"- quarterly_linear_interpolated.csv\")\n",
    "    print(\"- quarterly_linear_interpolated.xml\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e414514",
   "metadata": {},
   "outputs": [],
   "source": [
    "#My Anime List scarping script to get all animes by year including their mean and their number of"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4d2de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading entire MyAnimeList anime database...\n",
      "\n",
      "Fetching page 1 ...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     12\u001b[39m url = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mhttps://api.jikan.moe/v4/anime?page=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpage\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFetching page \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpage\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m ...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m response = \u001b[43mrequests\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# Rate limit handling\u001b[39;00m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m response.status_code == \u001b[32m429\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Han Aga\\Desktop\\dsa\\DSA 210 anime\\python.venv\\Lib\\site-packages\\requests\\api.py:73\u001b[39m, in \u001b[36mget\u001b[39m\u001b[34m(url, params, **kwargs)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget\u001b[39m(url, params=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m     63\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[32m     64\u001b[39m \n\u001b[32m     65\u001b[39m \u001b[33;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     70\u001b[39m \u001b[33;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mget\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Han Aga\\Desktop\\dsa\\DSA 210 anime\\python.venv\\Lib\\site-packages\\requests\\api.py:59\u001b[39m, in \u001b[36mrequest\u001b[39m\u001b[34m(method, url, **kwargs)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m sessions.Session() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Han Aga\\Desktop\\dsa\\DSA 210 anime\\python.venv\\Lib\\site-packages\\requests\\sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Han Aga\\Desktop\\dsa\\DSA 210 anime\\python.venv\\Lib\\site-packages\\requests\\sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    700\u001b[39m start = preferred_clock()\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[32m    706\u001b[39m elapsed = preferred_clock() - start\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Han Aga\\Desktop\\dsa\\DSA 210 anime\\python.venv\\Lib\\site-packages\\requests\\adapters.py:644\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    641\u001b[39m     timeout = TimeoutSauce(connect=timeout, read=timeout)\n\u001b[32m    643\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m644\u001b[39m     resp = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    645\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    646\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    647\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    648\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    651\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    652\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    653\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    654\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    655\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    656\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    658\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    659\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request=request)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Han Aga\\Desktop\\dsa\\DSA 210 anime\\python.venv\\Lib\\site-packages\\urllib3\\connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    784\u001b[39m response_conn = conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[32m    803\u001b[39m clean_exit = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Han Aga\\Desktop\\dsa\\DSA 210 anime\\python.venv\\Lib\\site-packages\\urllib3\\connectionpool.py:534\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    532\u001b[39m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[32m    533\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m534\u001b[39m     response = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    536\u001b[39m     \u001b[38;5;28mself\u001b[39m._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Han Aga\\Desktop\\dsa\\DSA 210 anime\\python.venv\\Lib\\site-packages\\urllib3\\connection.py:565\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    562\u001b[39m _shutdown = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.sock, \u001b[33m\"\u001b[39m\u001b[33mshutdown\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    564\u001b[39m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m565\u001b[39m httplib_response = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    567\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    568\u001b[39m     assert_header_parsing(httplib_response.msg)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\http\\client.py:1430\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1428\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1429\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1430\u001b[39m         \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1431\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[32m   1432\u001b[39m         \u001b[38;5;28mself\u001b[39m.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\http\\client.py:331\u001b[39m, in \u001b[36mHTTPResponse.begin\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    329\u001b[39m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[32m    330\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m331\u001b[39m     version, status, reason = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    332\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m status != CONTINUE:\n\u001b[32m    333\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\http\\client.py:292\u001b[39m, in \u001b[36mHTTPResponse._read_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    291\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m292\u001b[39m     line = \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[33m\"\u001b[39m\u001b[33miso-8859-1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    293\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) > _MAXLINE:\n\u001b[32m    294\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[33m\"\u001b[39m\u001b[33mstatus line\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\socket.py:719\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    717\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mcannot read from timed out object\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    718\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m719\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    720\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    721\u001b[39m     \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\ssl.py:1304\u001b[39m, in \u001b[36mSSLSocket.recv_into\u001b[39m\u001b[34m(self, buffer, nbytes, flags)\u001b[39m\n\u001b[32m   1300\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1301\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1302\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1303\u001b[39m           \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1304\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1305\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1306\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv_into(buffer, nbytes, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\ssl.py:1138\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1136\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1137\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1138\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1139\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1140\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import time\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "all_anime = []\n",
    "page = 1\n",
    "\n",
    "print(\"Downloading entire MyAnimeList anime database...\\n\")\n",
    "\n",
    "while True:\n",
    "    url = f\"https://api.jikan.moe/v4/anime?page={page}\"\n",
    "    print(f\"Fetching page {page} ...\")\n",
    "\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Rate limit handling\n",
    "    if response.status_code == 429:\n",
    "        print(\"Rate limited, waiting 2 seconds...\")\n",
    "        time.sleep(2)\n",
    "        continue\n",
    "\n",
    "    data = response.json()\n",
    "\n",
    "    if \"data\" not in data or len(data[\"data\"]) == 0:\n",
    "        print(\"\\n✔ Finished downloading all anime!\")\n",
    "        break\n",
    "\n",
    "    for anime in data[\"data\"]:\n",
    "        title = anime.get(\"title\")\n",
    "        score = anime.get(\"score\")\n",
    "        genres = [g[\"name\"] for g in anime.get(\"genres\", [])]\n",
    "        aired_from = anime.get(\"aired\", {}).get(\"from\")\n",
    "\n",
    "        if aired_from:\n",
    "            try:\n",
    "                date = datetime.fromisoformat(aired_from.replace(\"Z\", \"\"))\n",
    "                year = date.year\n",
    "                quarter = (date.month - 1) // 3 + 1\n",
    "                year_quarter = f\"{year}Q{quarter}\"\n",
    "            except Exception:\n",
    "                year = None\n",
    "                year_quarter = None\n",
    "        else:\n",
    "            year = None\n",
    "            year_quarter = None\n",
    "\n",
    "        all_anime.append({\n",
    "            \"title\": title,\n",
    "            \"score\": score,\n",
    "            \"year\": year,\n",
    "            \"year_quarter\": year_quarter\n",
    "        })\n",
    "\n",
    "    page += 1\n",
    "    time.sleep(1.1)  # Jikan rate limit\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# DataFrames\n",
    "# -----------------------\n",
    "\n",
    "df = pd.DataFrame(all_anime)\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "# -----------------------\n",
    "# Determine last completed quarter\n",
    "# -----------------------\n",
    "\n",
    "now = datetime.now()\n",
    "current_year = now.year\n",
    "current_quarter = (now.month - 1) // 3 + 1\n",
    "\n",
    "if current_quarter == 1:\n",
    "    last_year = current_year - 1\n",
    "    last_quarter = 4\n",
    "else:\n",
    "    last_year = current_year\n",
    "    last_quarter = current_quarter - 1\n",
    "\n",
    "last_completed_q = f\"{last_year}Q{last_quarter}\"\n",
    "\n",
    "print(f\"Using data up to: {last_completed_q}\")\n",
    "\n",
    "# -----------------------\n",
    "# Filter dataframe\n",
    "# -----------------------\n",
    "\n",
    "df[\"sort_key\"] = df[\"year_quarter\"].str.replace(\"Q\", \"\").astype(int)\n",
    "max_key = int(f\"{last_year}{last_quarter}\")\n",
    "\n",
    "df = df[df[\"sort_key\"] <= max_key]\n",
    "df = df.drop(columns=\"sort_key\")\n",
    "\n",
    "# Drop entries without quarter info\n",
    "df = df.dropna(subset=[\"year_quarter\"])\n",
    "\n",
    "# Quarterly aggregation\n",
    "quarterly_stats = df.groupby(\"year_quarter\").agg(\n",
    "    anime_count=(\"title\", \"count\"),\n",
    "    mean_score=(\"score\", \"mean\")\n",
    ").reset_index()\n",
    "\n",
    "# Sort properly (YYYYQn)\n",
    "quarterly_stats[\"sort_key\"] = quarterly_stats[\"year_quarter\"].str.replace(\"Q\", \"\").astype(int)\n",
    "quarterly_stats = quarterly_stats.sort_values(\"sort_key\").drop(columns=\"sort_key\")\n",
    "\n",
    "# -----------------------\n",
    "# Save files\n",
    "# -----------------------\n",
    "\n",
    "df.to_csv(\"all_anime_raw_quarterly.csv\", index=False)\n",
    "quarterly_stats.to_csv(\"anime_quarter_stats.csv\", index=False)\n",
    "\n",
    "print(\"\\n✔ Saved:\")\n",
    "print(\" - all_anime_raw_quarterly.csv\")\n",
    "print(\" - anime_quarter_stats.csv\")\n",
    "print(quarterly_stats.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5b2a5f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9dd2ee2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CORRELATION RESULTS ===\n",
      "Mean Score ↔ Market Value:  r = 0.3356, p = 5.0327e-03\n",
      "Anime Count ↔ Market Value: r = 0.7723, p = 0.0000e+00\n",
      "\n",
      "Saved results to correlation_results.txt\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Load datasets\n",
    "# -----------------------------\n",
    "anime = pd.read_csv(\"anime_year_stats.csv\")       # columns: year, anime_count, mean_score\n",
    "market = pd.read_csv(\"yearly_values.csv\")        # columns: Year, TotalValue_USD, etc.\n",
    "\n",
    "# Ensure column names match\n",
    "anime.rename(columns={\"year\": \"Year\"}, inplace=True)\n",
    "\n",
    "# Merge on Year\n",
    "df = anime.merge(market, on=\"Year\", how=\"inner\")\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Compute Pearson correlation manually\n",
    "# -----------------------------\n",
    "def pearson_corr(x, y):\n",
    "    x_mean = np.mean(x)\n",
    "    y_mean = np.mean(y)\n",
    "    numerator = np.sum((x - x_mean) * (y - y_mean))\n",
    "    denominator = np.sqrt(np.sum((x - x_mean)**2) * np.sum((y - y_mean)**2))\n",
    "    r = numerator / denominator\n",
    "    return r\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Compute two-tailed p-value from r\n",
    "# -----------------------------\n",
    "def pearson_p_value(r, n):\n",
    "    if n < 3:\n",
    "        return float('nan')\n",
    "    t_stat = r * math.sqrt((n - 2) / (1 - r**2))\n",
    "    # two-tailed p-value using normal approximation\n",
    "    p = 2 * (1 - 0.5 * (1 + math.erf(abs(t_stat) / math.sqrt(2))))\n",
    "    return p\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Compute correlations and p-values\n",
    "# -----------------------------\n",
    "n = len(df)\n",
    "\n",
    "# Mean score vs market value\n",
    "r_score = pearson_corr(df[\"mean_score\"], df[\"TotalValue_USD\"])\n",
    "p_score = pearson_p_value(r_score, n)\n",
    "\n",
    "# Anime count vs market value\n",
    "r_count = pearson_corr(df[\"anime_count\"], df[\"TotalValue_USD\"])\n",
    "p_count = pearson_p_value(r_count, n)\n",
    "\n",
    "# -----------------------------\n",
    "# 5. Print results\n",
    "# -----------------------------\n",
    "print(\"=== CORRELATION RESULTS ===\")\n",
    "print(f\"Mean Score ↔ Market Value:  r = {r_score:.4f}, p = {p_score:.4e}\")\n",
    "print(f\"Anime Count ↔ Market Value: r = {r_count:.4f}, p = {p_count:.4e}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 6. Save results to file (UTF-8)\n",
    "# -----------------------------\n",
    "with open(\"correlation_results.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"=== CORRELATION RESULTS ===\\n\\n\")\n",
    "    f.write(f\"Mean Score ↔ Market Value\\n  r = {r_score:.4f}\\n  p = {p_score:.4e}\\n\\n\")\n",
    "    f.write(f\"Anime Count ↔ Market Value\\n  r = {r_count:.4f}\\n  p = {p_count:.4e}\\n\")\n",
    "\n",
    "print(\"\\nSaved results to correlation_results.txt\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b29144",
   "metadata": {},
   "source": [
    "now the ml part for predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "af676652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Choose prediction mode:\n",
      "1 → Give anime count → predict money\n",
      "2 → Give money → predict anime count\n",
      "3 → Auto predict everything\n",
      "\n",
      "📊 AUTO 2026Q1 PREDICTION\n",
      "Predicted anime count : 279\n",
      "Predicted mean score  : 6.69\n",
      "Predicted market val  : $49,129,349,272,829\n",
      "Expected change       : 3.13%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "# -----------------------\n",
    "# LOAD DATA\n",
    "# -----------------------\n",
    "\n",
    "anime = pd.read_csv(\"anime_quarter_stats.csv\")\n",
    "stocks = pd.read_csv(\"quarterly_linear_interpolated.csv\")\n",
    "\n",
    "anime = anime.set_index(\"year_quarter\")\n",
    "stocks = stocks.set_index(\"index\")\n",
    "\n",
    "industry = stocks[\"TotalValue\"].dropna()\n",
    "\n",
    "# align indices\n",
    "quarters = anime.index.intersection(industry.index)\n",
    "anime = anime.loc[quarters]\n",
    "industry = industry.loc[quarters]\n",
    "\n",
    "def next_quarter_label(last_q):\n",
    "    year = int(last_q[:4])\n",
    "    quarter = int(last_q[-1])\n",
    "\n",
    "    now = datetime.now()\n",
    "    current_q = (now.month - 1) // 3 + 1\n",
    "\n",
    "    # if last known data is already behind current quarter,\n",
    "    # predict the current quarter instead of skipping ahead\n",
    "    if quarter < current_q or year < now.year:\n",
    "        return f\"{now.year}Q{current_q}\"\n",
    "\n",
    "    # otherwise predict the next quarter\n",
    "    if quarter == 4:\n",
    "        return f\"{year + 1}Q1\"\n",
    "    else:\n",
    "        return f\"{year}Q{quarter + 1}\"\n",
    "# -----------------------\n",
    "# HELPER: LINEAR REGRESSION (manual)\n",
    "# -----------------------\n",
    "\n",
    "def linear_regression(X, y, alpha=1.0):\n",
    "    X = np.column_stack([np.ones(len(X)), X])\n",
    "    I = np.eye(X.shape[1])\n",
    "    I[0, 0] = 0\n",
    "    return np.linalg.inv(X.T @ X + alpha * I) @ X.T @ y\n",
    "\n",
    "# -----------------------\n",
    "# 1️⃣ PREDICT ANIME COUNT (trend-based)\n",
    "# -----------------------\n",
    "\n",
    "t = np.arange(len(anime))\n",
    "w_count = linear_regression(t.reshape(-1, 1), anime[\"anime_count\"].values)\n",
    "pred_anime_count = max(1, int(w_count @ np.array([1, len(t)])))\n",
    "\n",
    "# -----------------------\n",
    "# 2️⃣ PREDICT MEAN SCORE (trend-based)\n",
    "# -----------------------\n",
    "\n",
    "w_score = linear_regression(t.reshape(-1, 1), anime[\"mean_score\"].values)\n",
    "pred_mean_score = float(w_score @ np.array([1, len(t)]))\n",
    "\n",
    "# -----------------------\n",
    "# 3️⃣ INDUSTRY IMPACT MODEL\n",
    "# -----------------------\n",
    "\n",
    "rows = []\n",
    "\n",
    "for i in range(1, len(quarters)):\n",
    "    q = quarters[i]\n",
    "    q_prev = quarters[i - 1]\n",
    "\n",
    "    rows.append({\n",
    "        \"anime_count\": anime.loc[q, \"anime_count\"],\n",
    "        \"mean_score\": anime.loc[q, \"mean_score\"],\n",
    "        \"target\": np.log(industry.loc[q] / industry.loc[q_prev])\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(rows).dropna()\n",
    "\n",
    "X = df[[\"anime_count\", \"mean_score\"]].values\n",
    "y = df[\"target\"].values\n",
    "\n",
    "w_market = linear_regression(X, y)\n",
    "\n",
    "# -----------------------\n",
    "# USER OPTION\n",
    "# -----------------------\n",
    "\n",
    "print(\"\\nChoose prediction mode:\")\n",
    "print(\"1 → Give anime count → predict money\")\n",
    "print(\"2 → Give money → predict anime count\")\n",
    "print(\"3 → Auto predict everything\")\n",
    "\n",
    "choice = input(\"Your choice (1/2/3): \").strip()\n",
    "\n",
    "last_value = industry.iloc[-1]\n",
    "\n",
    "if choice == \"1\":\n",
    "    user_anime = float(input(\"Enter expected anime count: \"))\n",
    "    user_score = float(input(\"Enter expected mean score: \"))\n",
    "\n",
    "    X_pred = np.array([1, user_anime, user_score])\n",
    "    delta = X_pred @ w_market\n",
    "    predicted_value = last_value * np.exp(delta)\n",
    "\n",
    "    print(f\"\\n📈 Predicted industry value: ${predicted_value:,.0f}\")\n",
    "\n",
    "elif choice == \"2\":\n",
    "    anime_est = -1\n",
    "\n",
    "    while anime_est < 0:\n",
    "        try:\n",
    "            user_money = float(input(\"Enter target industry value (USD): \"))\n",
    "\n",
    "            growth = np.log(user_money / last_value)\n",
    "\n",
    "            # solve for anime count (mean score fixed)\n",
    "            anime_est = (\n",
    "                growth\n",
    "                - w_market[0]\n",
    "                - w_market[2] * pred_mean_score\n",
    "            ) / w_market[1]\n",
    "\n",
    "            if anime_est < 0:\n",
    "                print(\"❌ Resulting anime count is negative — increase target value.\")\n",
    "\n",
    "        except ValueError:\n",
    "            print(\"❌ Please enter a valid number.\")\n",
    "\n",
    "    print(f\"\\n🎬 Required anime count: {anime_est:.0f}\")\n",
    "    print(f\"\\n🎬 Estimated anime count needed: {anime_est:.1f}\")\n",
    "    print(f\"Using mean score ≈ {pred_mean_score:.2f}\")\n",
    "\n",
    "else:\n",
    "    X_pred = np.array([1, pred_anime_count, pred_mean_score])\n",
    "    delta = X_pred @ w_market\n",
    "    predicted_value = last_value * np.exp(delta)\n",
    "    pct_change = (predicted_value / last_value - 1) * 100\n",
    "\n",
    "    predicted_q = next_quarter_label(industry.index[-1])\n",
    "\n",
    "    print(f\"\\n📊 AUTO {predicted_q} PREDICTION\")\n",
    "    print(f\"Predicted anime count : {pred_anime_count}\")\n",
    "    print(f\"Predicted mean score  : {pred_mean_score:.2f}\")\n",
    "    print(f\"Predicted market val  : ${predicted_value:,.0f}\")\n",
    "    print(f\"Expected change       : {pct_change:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6c665f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Visualization files exported\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# create folder if it doesn't exist\n",
    "output_dir = \"html_code\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "viz = pd.DataFrame({\n",
    "    \"quarter\": industry.index,\n",
    "    \"industry_value\": industry.values\n",
    "})\n",
    "\n",
    "viz.to_csv(f\"{output_dir}/industry_timeseries.csv\", index=False)\n",
    "\n",
    "params = {\n",
    "    \"w0\": w_market[0],\n",
    "    \"w1\": w_market[1],\n",
    "    \"w2\": w_market[2],\n",
    "    \"last_value\": float(last_value),\n",
    "    \"pred_mean_score\": float(pred_mean_score)\n",
    "}\n",
    "\n",
    "pd.Series(params).to_json(f\"{output_dir}/model_params.json\")\n",
    "\n",
    "print(\"✔ Visualization files exported to /html_code\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a0c82a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Han Aga\\Desktop\\dsa\\DSA 210 anime\\html code\n",
      "http://localhost:8000/\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "%cd \"C:/Users/Han Aga/Desktop/dsa/DSA 210 anime/html code\"\n",
    "print(\"http://localhost:8000/\")\n",
    "!python -m http.server 8000"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python.venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
